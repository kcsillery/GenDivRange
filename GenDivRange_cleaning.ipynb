{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30253a60",
   "metadata": {},
   "source": [
    "# GenDivRange Data Preprocessing Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b19f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules and dataframes\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spec_df = pd.read_excel(r'C:\\Users\\yanghao\\Dropbox\\DGS2020_DivHetMeta\\Haonan\\spec_upload_Haonan.xlsx')\n",
    "pop_df = pd.read_excel(r'C:\\Users\\yanghao\\Dropbox\\DGS2020_DivHetMeta\\Haonan\\pop_upload_Haonan.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193370e",
   "metadata": {},
   "source": [
    "Check the validity of parameters\n",
    "Sample size N must be an integer;<br />\n",
    "Expected and observed heterozygozities must be between 0 and 1;<br />\n",
    "The number of populations for each study must be at least 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check N is interger or NA\n",
    "pop_df.loc[(pd.isna(pop_df['N'])) & (pop_df['Study_id'].isin(spec_df.loc[-spec_df['Contributor'].isin(['MacroPopGen', 'VarVer']), 'Study_id'])), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f30709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Ho He Nei is between 0 and 1\n",
    "if sum(pop_df['Ho']>1) > 0:\n",
    "    print('Ho check failed\\n')\n",
    "    print(pop_df.loc[ (pop_df['Ho']>1) , ['Pop_id','Ho','He']])\n",
    "else:\n",
    "    print('\\nHo checked successful\\n')\n",
    "\n",
    "\n",
    "if sum(pop_df['He']>1) > 0:\n",
    "    print('\\nHe check failed\\n')\n",
    "    print(pop_df.loc[ (pop_df['He']>1) , ['Pop_id','Ho','He']])\n",
    "else:\n",
    "    print('\\nHe checked successful\\n')\n",
    "    \n",
    "if sum(pop_df['GD_Nei']>1) > 0:\n",
    "    print(\"\\nNei's diversity check failed\\n\")\n",
    "    print(pop_df.loc[ (pop_df['GD_Nei']>1) , ['Pop_id','GD_Nei']])\n",
    "else:\n",
    "    print(\"\\nNei's diversity checked successful\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d801e44",
   "metadata": {},
   "source": [
    "## Geog_1 at level of country\n",
    "We add a column named Geog_1 to indicate location of a population at the level of country, which is obtained either by country code or information from source paper or reverse geocoding from coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b490bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules and functions\n",
    "import requests\n",
    "\n",
    "def reverse_geocoder(Lat,Lon):\n",
    "    '''return a string of top 3 matching location\n",
    "    \n",
    "    Input Lat and Lon can be string or numeric'''\n",
    "    API_KEY = 'ENTER_YOUR_API_KEY'\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng='+str(Lat)+','+str(Lon)+'&key='+API_KEY\n",
    "    ini_string = ''\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "        if len(response['results']) <= 3:\n",
    "            for i in range(len(response['results'])):\n",
    "                ini_string += response['results'][i]['formatted_address'] + ' '\n",
    "        else:\n",
    "            for i in range(3):\n",
    "                ini_string += response['results'][i]['formatted_address'] + ' '\n",
    "\n",
    "        return ini_string\n",
    "    except:\n",
    "        return 'Error Found'\n",
    "\n",
    "def find_country(string):\n",
    "    '''find and return a country within a string of location \n",
    "    \n",
    "    input string should contains an address with country'''\n",
    "    \n",
    "    try:\n",
    "        if 'USA' in string or 'United States' in string:\n",
    "            return 'United States of America'\n",
    "        country_list = ['India', 'Uganda', 'Kenya', 'Tanzania', 'South Africa', 'Botswana','Namibia', 'Portugal', 'Netherlands', 'Czechia', 'Russia',\n",
    "        'Estonia', 'Latvia', 'Spain', 'Germany', 'Sweden', 'Norway', 'Finland', 'Switzerland', 'United States of America',\n",
    "        'United Kingdom', 'Atlantic Ocean ', 'Atlantic', 'Mexico', 'Malawi', 'Australia', 'Canada', 'Mediterranean Sea',\n",
    "        'Tyrrhenian Sea', 'Italy', 'Tunisia', 'Algeria', 'Mozambique', 'France', 'Brazil', 'Uruguay', 'Argentina', 'Japan', 'Greece',\n",
    "        'Romania', 'Turkey', 'Slovenia', 'Greenland ', 'Greenland', 'Greenland Sea', 'North Sea', 'Norwegian Sea', 'New Zealand',\n",
    "        'New Zealand ', 'Tasman Sea', 'Albania', 'Ghana', 'Zimbabwe', 'Zambia', 'Panama', 'Malaysia', 'Soma', 'Somalia', 'Belgium', 'Denmark', 'Irish Sea', 'Iceland', 'Senegal', 'Mongolia', 'China',\n",
    "        'Madagascar', 'Indonesia', 'Ireland', 'Ecuador', 'Poland', 'Egypt', 'Thailand', 'Singapore', 'Guatemala', 'Costa Rica',\n",
    "        'North Pacific Ocean', 'Cambodia', 'Vietnam', 'Peru', 'Colombia', 'Venezuela', 'Taiwan', 'South Korea', 'Caribbean Sea', 'Honduras',\n",
    "        'The Bahamas', 'United Kindom', 'Belize', 'South Pacific Ocean', 'Austria', 'Iran', 'Isle of Man', 'Eswatini', 'Hungary',\n",
    "        'Turkmenistan ', 'Kazakhstan', 'Montenegro', 'Bosnia and Herzegovina', 'Baltic Sea', 'Ethiopia',\n",
    "        'French Polynesia', 'Cook Islands', 'Fiji', 'Papua New Guinea', 'Morocco', 'Israel', 'Jordan', 'Slovakia', 'Bulgaria', 'Ukraine',\n",
    "        'Moldova', 'Niger', 'Barbados', 'Malta', 'Skagerrak', 'Vanuatu', 'Beaufort Sea', 'Antarctica', 'Weddell Sea', 'Réunion',\n",
    "        'Philippines', 'Guam', 'New Caledonia', 'Jamaica', 'North Atlantic Ocean', 'Georgia', 'Armenia', 'Alboran Sea',\n",
    "        'Serbia', 'Trinidad and Tobago', 'Paraguay', 'Myanmar', 'Cyprus', 'Bering Sea', 'Chile', 'American Samoa', 'Tyrrhenian Sea ',\n",
    "        'East Sea', 'Croatia', 'Beibu Gulf', 'Laos', \"Côte d'Ivoire\", 'South Sudan', 'Nicaragua', 'Bolivia', 'French Guiana', 'Puerto Rico', 'Cuba', 'Saint Lucia', 'Guyana']\n",
    "        for i in country_list:\n",
    "                if i in string:\n",
    "                    return i\n",
    "        if 'UK' in string or 'British' in string or 'Cayman Islands' in string or 'Montserrat' in string or 'Bermuda' in string or 'Falkland Islands' in string:\n",
    "            return 'United Kindom'\n",
    "        elif 'Dominican Republic' in string or 'Dominica' in string:\n",
    "            return 'Dominican Republic'\n",
    "        elif 'Jan Mayen' in string:\n",
    "            return 'Norway'\n",
    "        elif 'Guadeloupe' in string:\n",
    "            return 'France'\n",
    "    except:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d62be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column 'api' to store the address obatined from google map api using coordinates\n",
    "pop_df['api'] = ''\n",
    "for i in range(len(pop_df)):\n",
    "    Lat = pop_df.at[i,'Latitude']\n",
    "    Lon = pop_df.at[i,'Longitude']\n",
    "    pop_df.at[i,'api'] = reverse_geocoder(Lat, Lon)\n",
    "    if i % 1000 == 0:\n",
    "        print('now finished at ', i, ' with study id: ', pop_df.loc[i,'Study_id'])\n",
    "\n",
    "# extract key word country using function find_country\n",
    "for i in range(len(pop_df)):\n",
    "    pop_df.at[i,'Geog_1'] = find_country(pop_df.at[i,'api'])\n",
    "    if i % 1000 == 0:\n",
    "        print('currently at: ', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71750e06",
   "metadata": {},
   "source": [
    "## Spec_id\n",
    "Since we assign every species an id, i.e., a four-letter code to uniquely represent the species. This section checks if a species id conrresponds to a species uniquely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abb = dict()\n",
    "try:\n",
    "    for i in range( len(spec_df) ):\n",
    "        if spec_df.at[i,'Spec_id'] not in abb.keys():\n",
    "            abb[ spec_df.at[i,'Spec_id'] ] = spec_df.at[i,'Species']\n",
    "        else:\n",
    "            if spec_df.at[i,'Species'] != abb[ spec_df.at[i,'Spec_id'] ]:\n",
    "                raise Exception\n",
    "except:\n",
    "    print('found mismatch between:', spec_df.at[i,'Species'], ' and ', abb[ spec_df.at[i,'Spec_id']])\n",
    "else:\n",
    "    print('Study_id uniqueness checked')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47919d02",
   "metadata": {},
   "source": [
    "## Fishbase\n",
    "Key words are extracted from fishbase database in order to determine habitat later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions and module\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def fishbase(species):\n",
    "    '''return classfication and environment of the species if found in fishbase.de\n",
    "    \n",
    "    input a species (in 'Genus species' format)'''\n",
    "    def replace_all(text,dict):\n",
    "        for key,value in dict.items():\n",
    "            text = text.replace(key,value)\n",
    "        return text\n",
    "\n",
    "    dict = {'usually':'', ' depth range ':'', ';c':'', ';n':'', ';s':'', ';e':'', ';w':'', 'temperature':'', ' ph range:':'', ' dh range:':'', '; ,   .':'', ';;':'', '?':'', '..;':'', '  ; ':'',' , ':''}\n",
    "    try:\n",
    "        spec = species.replace(' ','-')\n",
    "        url = \"https://www.fishbase.de/summary/\" + spec + \".html\"\n",
    "        request = requests.get(url)\n",
    "        if request.ok:\n",
    "            s = request.text\n",
    "            start = \"<!-- start Environment / Climate / Range -->\"\n",
    "            end = \"<!-- start Distribution -->\"\n",
    "            target = s[s.find(start)+len(start):s.rfind(end)].lower()   # this extracts the Environment partition\n",
    "            if 'species name is not in the public version of fishbase' in target:\n",
    "                return 'Not found'\n",
    "            taxa = re.sub(r'<.*?>' ,'', re.sub(r'[(\\r)(\\n)(\\t)0-9]','',target) ).replace('environment: milieu / climate zone / depth range / distribution rangeecology','').replace('&deg','').replace(' - ','').replace('&nbsp','').replace('ref.','').replace(' m ','')\n",
    "            result = replace_all(taxa, dict)\n",
    "            return result\n",
    "        else:\n",
    "            return 'Format incorrect'\n",
    "    except:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5706400",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['fishbase'] = ''\n",
    "for i in range(len(spec_df)):\n",
    "    spec_df.at[i,'fishbase'] = fishbase(spec_df.at[i,'Species'])\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9192ffe",
   "metadata": {},
   "source": [
    "## EOL dababase\n",
    "We extract many useful information of each species from EOL database, e.g., the common name, and short overview of the species. Addtionally, we also recorded teh species page url of the EOl database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules needed\n",
    "import os\n",
    "import requests\n",
    "import wget\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['found'] = [None] * len(spec_df)\n",
    "spec_df['common_name'] = [None] * len(spec_df)\n",
    "spec_df['page_id'] = [None] * len(spec_df)\n",
    "spec_df['overview'] = [None] * len(spec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://eol.org/'\n",
    "options = Options()\n",
    "options.add_argument(\"user-data-dir=C:\\\\Users\\\\yanghao\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Profile 2\")\n",
    "options.add_argument('headless') # not open the browser\n",
    "\n",
    "for i in range( len(spec_df) ):\n",
    "    spec_name = spec_df.at[i,'Species']\n",
    "    driver = webdriver.Chrome('C:\\\\Users\\\\yanghao\\\\Anaconda3\\\\chromedriver.exe', options=options)\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(2)\n",
    "    className = driver.find_element_by_name(\"q\")\n",
    "    className.send_keys(spec_name + '\\n')\n",
    "    try:\n",
    "        res = driver.find_element_by_xpath(\"(//ul[@class='search-results js-search-results']/li)[contains(a,'Creatures')]\").click()\n",
    "        spec_df.at[i,'found'] = True\n",
    "        # Now at final page of desired info\n",
    "        spec_df.at[i,'page_id'] = driver.current_url\n",
    "        \n",
    "        try:\n",
    "            spec_df.at[i,'common_name'] = driver.find_element_by_tag_name('h1').text\n",
    "        except NoSuchElementException:\n",
    "            spec_df.at[i,'common_name'] = 'not found'\n",
    "\n",
    "        try:\n",
    "            spec_df.at[i,'full_latin'] = driver.find_element_by_tag_name('h2').text\n",
    "        except NoSuchElementException:\n",
    "            spec_df.at[i,'full_latin'] = 'not found'\n",
    "\n",
    "        try:\n",
    "            desc = driver.find_element_by_xpath(\"(//*[@class='desc']/p)[1]\").text\n",
    "            spec_df.at[i,'overview'] = desc\n",
    "        except NoSuchElementException:\n",
    "            spec_df.at[i,'overview'] = 'not found'\n",
    "\n",
    "    except:\n",
    "        spec_df.at[i,'found'] = False\n",
    "    finally:\n",
    "        sleep(1)\n",
    "    if i % 20 == 0:\n",
    "        print('now finished at ', i, ' with species: ', spec_df.loc[i,'Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ab172",
   "metadata": {},
   "source": [
    "## Number of loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "### When a species was collected by ourselves, the number of loci is manually searched via source paper and recorded\n",
    "\n",
    "### Obtain the number of loci for Varver database\n",
    "loci_df = pd.read_excel(r'C:\\Users\\yanghao\\Downloads\\VarVerDB_python_copy\\varver_extract_output_haonan_add_loci.xlsx')\n",
    "spec_var_df['loci'] = [None] * len(spec_var_df)\n",
    "# these species' number of loci varies among populations\n",
    "temp_dict = dict()\n",
    "for i in range(len(loci_df)):\n",
    "    if loci_df.at[i,'Varver'] not in temp_dict.keys():\n",
    "        temp_dict[ loci_df.at[i,'Varver'] ] = loci_df.at[i,'num_loci']\n",
    "    elif temp_dict[ loci_df.at[i,'Varver'] ] == loci_df.at[i,'num_loci']:\n",
    "        continue\n",
    "    else:\n",
    "        print( 'dict value error at varver html: {}'.format(loci_df.at[i,'Varver']))\n",
    "\n",
    "for i in range(len(spec_var_df)):\n",
    "    spec_var_df.at[i,'loci'] = temp_dict[ spec_var_df.at[i,'Reference'] ]\n",
    "\n",
    "spec_var_df.to_excel(r'C:\\Users\\yanghao\\Dropbox\\DGS2020_DivHetMeta\\Haonan\\varver_spec_loci_temp.xlsx')\n",
    "\n",
    "### Obtain the number of loci for MacroPopGen database\n",
    "macro_df = pd.read_excel(r'C:\\Users\\yanghao\\Dropbox\\DGS2020_DivHetMeta\\Haonan\\macro_Haonan.xlsx')\n",
    "\n",
    "def all_same(items):\n",
    "    return all(x == items[0] for x in items)\n",
    "\n",
    "for i in list(spec_df.loc[spec_df['Contributor'] == 'MacroPopGen',:].index): # loop through species from MacroPopGen\n",
    "    temp_df = macro_df[ macro_df.Study_id == spec_df.at[i,'Study_id']]\n",
    "    if all_same(list(temp_df.N_genotype)):\n",
    "        spec_df.at[i,'loci'] = pd.unique(temp_df.N_genotype)[0]\n",
    "    else:  # not all num_loci are the same, i.e., len(pd.unique(temp_df.N_genotype))>1\n",
    "        spec_df.at[i,'loci'] = max(pd.unique(temp_df.N_genotype))  # assign the highest number as loci number\n",
    "        print( f\"{spec_df.at[i,'Study_id']} has multiple num_loci {pd.unique(temp_df.N_genotype)}, as a result, {max(pd.unique(temp_df.N_genotype))} is assigned\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9258b18",
   "metadata": {},
   "source": [
    "## Taxonomy\n",
    "\n",
    "Taxonomy is extracted from overview text from EOL database. In total, species are categorized into 14 Taxonomy classes (Birds, Fishes, Amphibians, Mammals, Reptiles, Woody plants, Other inverebrates, Algae, Herbaceous plants, Molluscs, Crustaceans, Insects, Mosses, and Fungi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['Taxonomy'] = [None] * len(spec_df)\n",
    "\n",
    "for i in range(len(spec_df)):\n",
    "    try:\n",
    "        spec_df.at[i,'Taxonomy'] = re.search('.*?is a s.*?pecies of (.*?) in the', spec_df.overview[i]).group(1)\n",
    "    except:\n",
    "        spec_df.at[i,'Taxonomy'] = 'Not found'\n",
    "    if i % 200 == 0:\n",
    "        print('now finished at ', i, ' with species: ', spec_df.loc[i,'Species'])\n",
    "\n",
    "taxo_dict = {\n",
    "    'birds':'Birds',\n",
    "    'bony fishes':'Fishes',\n",
    "    'amphibians':'Amphibians',\n",
    "    'mammals':'Mammals',\n",
    "    'crocodilians':'Reptiles',\n",
    "    'snakes':'Reptiles',\n",
    "    'rodents':'Mammals',\n",
    "    'turtles':'Reptiles',\n",
    "    'Squamata':'Reptiles',\n",
    "    'lampreys':'Fishes',\n",
    "    'tree':'Woody plants',\n",
    "    'annual herb':'Herbaceous plants',\n",
    "    'perennial herb':'Herbaceous plants',\n",
    "    'herb':'Herbaceous plants',\n",
    "    'shrub':'Woody plants',\n",
    "    'grass':'Herbaceous plants',\n",
    "    'annual grass':'Herbaceous plants',\n",
    "    'woody plants':'Woody plants',\n",
    "    'echinoderms':'Other inverebrates',\n",
    "    'dinoflagellates':'Algae',\n",
    "    'Gastropoda':'Molluscs',\n",
    "    'decapods':'Crustaceans',\n",
    "    'comb jellies':'Other inverebrates',\n",
    "    'mussels':'Molluscs',\n",
    "    'cnidarians':'Other inverebrates',\n",
    "    'segmented worms':'Other inverebrates',\n",
    "    'arrow worms':'Other inverebrates',\n",
    "    'Lepidoptera':'Insects',\n",
    "    'beetles':'Insects',\n",
    "    'Cicadomorpha':'Insects',\n",
    "    'primates':'Mammals',\n",
    "    'bats':'Mammals',\n",
    "    'mosses':'Mosses',\n",
    "    'flies':'Insects',\n",
    "    'modern sharks':'Fishes',\n",
    "    'true bugs':'Insects',\n",
    "    'rays':'Fishes',\n",
    "    'Hymenoptera':'Insects',\n",
    "    'nematodes':'Other inverebrates',\n",
    "    'Myliobatiformes':'Fishes'   \n",
    "}\n",
    "\n",
    "for i in range(len(spec_df)):\n",
    "    if spec_df.at[i,'Taxonomy'] in taxo_dict.keys():\n",
    "        spec_df.at[i,'Taxonomy'] = taxo_dict[ spec_df.at[i,'Taxonomy'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61ee53",
   "metadata": {},
   "source": [
    " ## BIOME from WWF Terrestrial Ecoregions of the World\n",
    " This section fills the column named BIOME that indicates the terrestrial ecoregions for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d891a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function and module required\n",
    "import geopandas as gpd\n",
    "\n",
    "def get_BIOME(df, LonColIdx, LatColIdx, path = \"C:\\\\Users\\\\yanghao\\\\Downloads\\\\ecology_map\\\\official\\\\wwf_terr_ecos.shp\"):\n",
    "    '''\n",
    "    Get Terrestrial ecosystems and BIOME from WWF based on coordinates. Geopandas required; wwf_terr_ecos.shp required \n",
    "    \n",
    "    Parameters:\n",
    "        df: input dataframe which include coordinates (assume EPSG:4326)\n",
    "        LonColIdx: column index of the DD format of Longitude\n",
    "        LatColIdx: column index of the DD format of Latitude\n",
    "        path: the path of of file wwf_terr_ecos.shp\n",
    "\n",
    "    Return:\n",
    "        The DataFrame with two additional columns indicating detailed ecology name and BIOME\n",
    "    '''\n",
    "\n",
    "    # check if input LonColIdx or LatColIdx is int\n",
    "    if (type(LonColIdx) is not int) | (type(LatColIdx) is not int):\n",
    "        raise TypeError('input LonColIdx or LatColIdx must be Int')\n",
    "\n",
    "    wwf = gpd.read_file(path).to_crs('EPSG:4326')\n",
    "    df2 = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.iloc[:,LonColIdx], df.iloc[:,LatColIdx]))\n",
    "    df2.crs = 'EPSG:4326'\n",
    "    df2['wwf_ecology'] = ''\n",
    "    df2['BIOME_num'] = ''\n",
    "    df2['BIOME'] = ''\n",
    "\n",
    "    habitat_dict = {\n",
    "        1: 'Tropical & Subtropical Moist Broadleaf Forests',\n",
    "        2: 'Tropical & Subtropical Dry Broadleaf Forests',\n",
    "        3: 'Tropical & Subtropical Coniferous Forests',\n",
    "        4: 'Temperate Broadleaf & Mixed Forests',\n",
    "        5: 'Temperate Conifer Forests',\n",
    "        6: 'Boreal Forests/Taiga',\n",
    "        7: 'Tropical & Subtropical Grasslands, Savannas & Shrublands',\n",
    "        8: 'Temperate Grasslands, Savannas & Shrublands',\n",
    "        9: 'Flooded Grasslands & Savannas',\n",
    "        10: 'Montane Grasslands & Shrublands',\n",
    "        11: 'Tundra',\n",
    "        12: 'Mediterranean Forests, Woodlands & Scrub',\n",
    "        13: 'Deserts & Xeric Shrublands',\n",
    "        14: 'Mangroves',\n",
    "        98: 'Lake',\n",
    "        99: 'Rock and Ice',\n",
    "        100: 'Others'\n",
    "    }\n",
    "\n",
    "    for i in range(len(df2)):\n",
    "            for j in range(len(wwf)):\n",
    "                if df2.at[i,'geometry'].within(wwf.at[j,'geometry']):\n",
    "                    df2.at[i,'wwf_ecology'] = wwf.at[j,'ECO_NAME']\n",
    "                    df2.at[i,'BIOME_num'] = wwf.at[j,'BIOME']\n",
    "                    df2.at[i,'BIOME'] = habitat_dict[ df2.at[i,'BIOME_num'] ]\n",
    "                    break\n",
    "            else:\n",
    "                df2.at[i,'wwf_ecology'] = 'unknown'\n",
    "                df2.at[i,'BIOME_num'] = 100\n",
    "                df2.at[i,'BIOME'] = 'Others'\n",
    "    \n",
    "    return df2\n",
    "\n",
    "# load occurrence data for each species, which is obtained from GBIF DATABASE\n",
    "\n",
    "occurrence_df = pd.read_csv(r'PATH_TO_OCCURRENCE_DATASET') # Obtained from GBIF database; see R script \n",
    "occurrence_df2 = get_BIOME(occurrence_df, LonColIdx, LatColIdx)\n",
    "summary = occurrence_df2.groupby('Species')['BIOME'].value_counts().unstack().fillna(0)\n",
    "\n",
    "summary2 = summary.copy()\n",
    "summary['BIOME'] = ''\n",
    "\n",
    "for i in list(pd.unique(occurrence_df2['Species'])):\n",
    "    summary.at[i,'BIOME'] = summary2.loc[i,].idxmax()\n",
    "\n",
    "summary['Species'] = summary.index\n",
    "spec_df.merge(summary.loc[:,['Species', 'BIOME']], how = 'left', on = 'Species')\n",
    "\n",
    "# For these species that have no occurrences data on GBIF, we use populations coordinates to obtain the BIOME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce4056",
   "metadata": {},
   "source": [
    "## Number of population\n",
    "This section extract the number of populations for each species; and check if there are at least five populations included per study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f973209",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pop_df.groupby('Study_id')['Spec_id'].value_counts()\n",
    "pop_num = []\n",
    "for i in range(len(new_df)):\n",
    "    pop_num.append((new_df.index[i][0], new_df[i]))\n",
    "pop_num_df = pd.DataFrame(dict(pop_num), columns = ['Study_id', 'num_of_populations'])\n",
    "spec_df.merge(pop_num_df, on = 'Study_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of population is at least 5\n",
    "if sum(spec_df['number of populations'] < 5) > 0:\n",
    "    print('number of populations check failed\\n')\n",
    "    print(spec_df.loc[spec_df['number of populations']<5 ,['Contributor', 'Species', 'Spec_id', 'Study_id', 'number of populations']])\n",
    "else:\n",
    "    print('\\nnumber of populations checked successful\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4261a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# have to further process this to remove those with N < 5\n",
    "spec_df.loc[spec_df['number of populations']<5 ,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6817c0",
   "metadata": {},
   "source": [
    "## Habitat_breeding & Habitat_adulthood\n",
    "Given the speciaty of some fish species, we decided to split the Habitat column into Habitat_breeding & Habitat_adulthood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60207c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['Habitat_breeding'] = ''\n",
    "spec_df['Habitat_adulthood'] = ''\n",
    "\n",
    "for i in range(len(spec_df)):\n",
    "    if spec_df.at[i,'Taxonomy'] in ['Birds', 'Reptiles', 'Woody plants','Herbaceous plants','Insects','Mosses','Fungi']:\n",
    "        spec_df.at[i, 'Habitat_breeding'] = 'Terrestrial'\n",
    "        spec_df.at[i, 'Habitat_adulthood'] = 'Terrestrial'\n",
    "    elif spec_df.at[i,'Taxonomy'] == 'Amphibians':\n",
    "        spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "        spec_df.at[i, 'Habitat_adulthood'] = 'Terrestrial'\n",
    "    elif spec_df.at[i,'Taxonomy'] == 'Fishes':\n",
    "        if 'potamodromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Freshwater'\n",
    "        elif 'anadromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Marine'\n",
    "        elif 'catadromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Marine'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Freshwater'\n",
    "        elif 'amphidromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = ''\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = ''\n",
    "        elif 'oceanodromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Marine'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Marine'\n",
    "        elif ('marine' in spec_df.at[i,'fishbase']) & ('freshwater' not in spec_df.at[i,'fishbase']):\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Marine'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Marine'\n",
    "        elif ('freshwater' in spec_df.at[i,'fishbase']) & ('marine' not in spec_df.at[i,'fishbase']):\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Freshwater'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24320228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spec_df.to_excel('species_upload_HabitatNotCompleted.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
