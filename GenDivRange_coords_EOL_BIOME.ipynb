{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30253a60",
   "metadata": {},
   "source": [
    "# GenDivRange Data Preprocessing Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b19f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules and dataframes\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spec_df = pd.read_excel(r'spec_tab_***.xlsx')\n",
    "pop_df = pd.read_excel(r'pop_tab_***.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d801e44",
   "metadata": {},
   "source": [
    "## Geog_1 at level of country\n",
    "We add a column named Geog_1 to indicate location of a population at the level of country, which is obtained either by country code or information from source paper or reverse geocoding from coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b490bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules and functions\n",
    "import requests\n",
    "\n",
    "def reverse_geocoder(Lat,Lon):\n",
    "    '''return a string of top 3 matching location\n",
    "    \n",
    "    Input Lat and Lon can be string or numeric'''\n",
    "    API_KEY = 'ENTER_YOUR_API_KEY'\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng='+str(Lat)+','+str(Lon)+'&key='+API_KEY\n",
    "    ini_string = ''\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "        if len(response['results']) <= 3:\n",
    "            for i in range(len(response['results'])):\n",
    "                ini_string += response['results'][i]['formatted_address'] + ' '\n",
    "        else:\n",
    "            for i in range(3):\n",
    "                ini_string += response['results'][i]['formatted_address'] + ' '\n",
    "\n",
    "        return ini_string\n",
    "    except:\n",
    "        return 'Error Found'\n",
    "\n",
    "def find_country(string):\n",
    "    '''find and return a country within a string of location \n",
    "    \n",
    "    input string should contains an address with country'''\n",
    "    \n",
    "    try:\n",
    "        if 'USA' in string or 'United States' in string:\n",
    "            return 'United States of America'\n",
    "        country_list = ['India', 'Uganda', 'Kenya', 'Tanzania', 'South Africa', 'Botswana','Namibia', 'Portugal', 'Netherlands', 'Czechia', 'Russia',\n",
    "        'Estonia', 'Latvia', 'Spain', 'Germany', 'Sweden', 'Norway', 'Finland', 'Switzerland', 'United States of America',\n",
    "        'United Kingdom', 'Atlantic Ocean ', 'Atlantic', 'Mexico', 'Malawi', 'Australia', 'Canada', 'Mediterranean Sea',\n",
    "        'Tyrrhenian Sea', 'Italy', 'Tunisia', 'Algeria', 'Mozambique', 'France', 'Brazil', 'Uruguay', 'Argentina', 'Japan', 'Greece',\n",
    "        'Romania', 'Turkey', 'Slovenia', 'Greenland ', 'Greenland', 'Greenland Sea', 'North Sea', 'Norwegian Sea', 'New Zealand',\n",
    "        'New Zealand ', 'Tasman Sea', 'Albania', 'Ghana', 'Zimbabwe', 'Zambia', 'Panama', 'Malaysia', 'Soma', 'Somalia', 'Belgium', 'Denmark', 'Irish Sea', 'Iceland', 'Senegal', 'Mongolia', 'China',\n",
    "        'Madagascar', 'Indonesia', 'Ireland', 'Ecuador', 'Poland', 'Egypt', 'Thailand', 'Singapore', 'Guatemala', 'Costa Rica',\n",
    "        'North Pacific Ocean', 'Cambodia', 'Vietnam', 'Peru', 'Colombia', 'Venezuela', 'Taiwan', 'South Korea', 'Caribbean Sea', 'Honduras',\n",
    "        'The Bahamas', 'United Kindom', 'Belize', 'South Pacific Ocean', 'Austria', 'Iran', 'Isle of Man', 'Eswatini', 'Hungary',\n",
    "        'Turkmenistan ', 'Kazakhstan', 'Montenegro', 'Bosnia and Herzegovina', 'Baltic Sea', 'Ethiopia',\n",
    "        'French Polynesia', 'Cook Islands', 'Fiji', 'Papua New Guinea', 'Morocco', 'Israel', 'Jordan', 'Slovakia', 'Bulgaria', 'Ukraine',\n",
    "        'Moldova', 'Niger', 'Barbados', 'Malta', 'Skagerrak', 'Vanuatu', 'Beaufort Sea', 'Antarctica', 'Weddell Sea', 'Réunion',\n",
    "        'Philippines', 'Guam', 'New Caledonia', 'Jamaica', 'North Atlantic Ocean', 'Georgia', 'Armenia', 'Alboran Sea',\n",
    "        'Serbia', 'Trinidad and Tobago', 'Paraguay', 'Myanmar', 'Cyprus', 'Bering Sea', 'Chile', 'American Samoa', 'Tyrrhenian Sea ',\n",
    "        'East Sea', 'Croatia', 'Beibu Gulf', 'Laos', \"Côte d'Ivoire\", 'South Sudan', 'Nicaragua', 'Bolivia', 'French Guiana', 'Puerto Rico', 'Cuba', 'Saint Lucia', 'Guyana']\n",
    "        for i in country_list:\n",
    "                if i in string:\n",
    "                    return i\n",
    "        if 'UK' in string or 'British' in string or 'Cayman Islands' in string or 'Montserrat' in string or 'Bermuda' in string or 'Falkland Islands' in string:\n",
    "            return 'United Kindom'\n",
    "        elif 'Dominican Republic' in string or 'Dominica' in string:\n",
    "            return 'Dominican Republic'\n",
    "        elif 'Jan Mayen' in string:\n",
    "            return 'Norway'\n",
    "        elif 'Guadeloupe' in string:\n",
    "            return 'France'\n",
    "    except:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d62be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column 'api' to store the address obatined from google map api using coordinates\n",
    "pop_df['api'] = ''\n",
    "for i in range(len(pop_df)):\n",
    "    Lat = pop_df.at[i,'Latitude']\n",
    "    Lon = pop_df.at[i,'Longitude']\n",
    "    pop_df.at[i,'api'] = reverse_geocoder(Lat, Lon)\n",
    "    if i % 1000 == 0:\n",
    "        print('now finished at ', i, ' with study id: ', pop_df.loc[i,'Study_id'])\n",
    "\n",
    "# extract key word country using function find_country\n",
    "for i in range(len(pop_df)):\n",
    "    pop_df.at[i,'Geog_1'] = find_country(pop_df.at[i,'api'])\n",
    "    if i % 1000 == 0:\n",
    "        print('currently at: ', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47919d02",
   "metadata": {},
   "source": [
    "## Fishbase\n",
    "Key words are extracted from fishbase database in order to determine habitat later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions and module\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def fishbase(species):\n",
    "    '''return classfication and environment of the species if found in fishbase.de\n",
    "    \n",
    "    input a species (in 'Genus species' format)'''\n",
    "    def replace_all(text,dict):\n",
    "        for key,value in dict.items():\n",
    "            text = text.replace(key,value)\n",
    "        return text\n",
    "\n",
    "    dict = {'usually':'', ' depth range ':'', ';c':'', ';n':'', ';s':'', ';e':'', ';w':'', 'temperature':'', ' ph range:':'', ' dh range:':'', '; ,   .':'', ';;':'', '?':'', '..;':'', '  ; ':'',' , ':''}\n",
    "    try:\n",
    "        spec = species.replace(' ','-')\n",
    "        url = \"https://www.fishbase.de/summary/\" + spec + \".html\"\n",
    "        request = requests.get(url)\n",
    "        if request.ok:\n",
    "            s = request.text\n",
    "            start = \"<!-- start Environment / Climate / Range -->\"\n",
    "            end = \"<!-- start Distribution -->\"\n",
    "            target = s[s.find(start)+len(start):s.rfind(end)].lower()   # this extracts the Environment partition\n",
    "            if 'species name is not in the public version of fishbase' in target:\n",
    "                return 'Not found'\n",
    "            taxa = re.sub(r'<.*?>' ,'', re.sub(r'[(\\r)(\\n)(\\t)0-9]','',target) ).replace('environment: milieu / climate zone / depth range / distribution rangeecology','').replace('&deg','').replace(' - ','').replace('&nbsp','').replace('ref.','').replace(' m ','')\n",
    "            result = replace_all(taxa, dict)\n",
    "            return result\n",
    "        else:\n",
    "            return 'Format incorrect'\n",
    "    except:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5706400",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['fishbase'] = ''\n",
    "for i in range(len(spec_df)):\n",
    "    spec_df.at[i,'fishbase'] = fishbase(spec_df.at[i,'Species'])\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9192ffe",
   "metadata": {},
   "source": [
    "## EOL dababase\n",
    "We extract many useful information of each species from EOL database, e.g., the common name, and short overview of the species. Addtionally, we also recorded teh species page url of the EOl database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules needed\n",
    "import os\n",
    "import requests\n",
    "import wget\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['found'] = [None] * len(spec_df)\n",
    "spec_df['common_name'] = [None] * len(spec_df)\n",
    "spec_df['page_id'] = [None] * len(spec_df)\n",
    "spec_df['overview'] = [None] * len(spec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://eol.org/'\n",
    "options = Options()\n",
    "options.add_argument(\"user-data-dir=C:\\\\Users\\\\yanghao\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Profile 2\")\n",
    "options.add_argument('headless') # not open the browser\n",
    "\n",
    "for i in range( len(spec_df) ):\n",
    "    spec_name = spec_df.at[i,'Species']\n",
    "    driver = webdriver.Chrome('C:\\\\Users\\\\yanghao\\\\Anaconda3\\\\chromedriver.exe', options=options)\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(2)\n",
    "    className = driver.find_element_by_name(\"q\")\n",
    "    className.send_keys(spec_name + '\\n')\n",
    "    try:\n",
    "        res = driver.find_element_by_xpath(\"(//ul[@class='search-results js-search-results']/li)[contains(a,'Creatures')]\").click()\n",
    "        spec_df.at[i,'found'] = True\n",
    "        # Now at final page of desired info\n",
    "        spec_df.at[i,'page_id'] = driver.current_url\n",
    "        \n",
    "        try:\n",
    "            spec_df.at[i,'common_name'] = driver.find_element_by_tag_name('h1').text\n",
    "        except NoSuchElementException:\n",
    "            spec_df.at[i,'common_name'] = 'not found'\n",
    "\n",
    "        try:\n",
    "            spec_df.at[i,'full_latin'] = driver.find_element_by_tag_name('h2').text\n",
    "        except NoSuchElementException:\n",
    "            spec_df.at[i,'full_latin'] = 'not found'\n",
    "\n",
    "        try:\n",
    "            desc = driver.find_element_by_xpath(\"(//*[@class='desc']/p)[1]\").text\n",
    "            spec_df.at[i,'overview'] = desc\n",
    "        except NoSuchElementException:\n",
    "            spec_df.at[i,'overview'] = 'not found'\n",
    "\n",
    "    except:\n",
    "        spec_df.at[i,'found'] = False\n",
    "    finally:\n",
    "        sleep(1)\n",
    "    if i % 20 == 0:\n",
    "        print('now finished at ', i, ' with species: ', spec_df.loc[i,'Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ab172",
   "metadata": {},
   "source": [
    "## Number of loci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9258b18",
   "metadata": {},
   "source": [
    "## Taxonomy\n",
    "\n",
    "Taxonomy is extracted from overview text from EOL database. In total, species are categorized into 14 Taxonomy classes (Birds, Fishes, Amphibians, Mammals, Reptiles, Woody plants, Other inverebrates, Algae, Herbaceous plants, Molluscs, Crustaceans, Insects, Mosses, and Fungi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['Taxonomy'] = [None] * len(spec_df)\n",
    "\n",
    "for i in range(len(spec_df)):\n",
    "    try:\n",
    "        spec_df.at[i,'Taxonomy'] = re.search('.*?is a s.*?pecies of (.*?) in the', spec_df.overview[i]).group(1)\n",
    "    except:\n",
    "        spec_df.at[i,'Taxonomy'] = 'Not found'\n",
    "    if i % 200 == 0:\n",
    "        print('now finished at ', i, ' with species: ', spec_df.loc[i,'Species'])\n",
    "\n",
    "taxo_dict = {\n",
    "    'birds':'Birds',\n",
    "    'bony fishes':'Fishes',\n",
    "    'amphibians':'Amphibians',\n",
    "    'mammals':'Mammals',\n",
    "    'crocodilians':'Reptiles',\n",
    "    'snakes':'Reptiles',\n",
    "    'rodents':'Mammals',\n",
    "    'turtles':'Reptiles',\n",
    "    'Squamata':'Reptiles',\n",
    "    'lampreys':'Fishes',\n",
    "    'tree':'Woody plants',\n",
    "    'annual herb':'Herbaceous plants',\n",
    "    'perennial herb':'Herbaceous plants',\n",
    "    'herb':'Herbaceous plants',\n",
    "    'shrub':'Woody plants',\n",
    "    'grass':'Herbaceous plants',\n",
    "    'annual grass':'Herbaceous plants',\n",
    "    'woody plants':'Woody plants',\n",
    "    'echinoderms':'Other inverebrates',\n",
    "    'dinoflagellates':'Algae',\n",
    "    'Gastropoda':'Molluscs',\n",
    "    'decapods':'Crustaceans',\n",
    "    'comb jellies':'Other inverebrates',\n",
    "    'mussels':'Molluscs',\n",
    "    'cnidarians':'Other inverebrates',\n",
    "    'segmented worms':'Other inverebrates',\n",
    "    'arrow worms':'Other inverebrates',\n",
    "    'Lepidoptera':'Insects',\n",
    "    'beetles':'Insects',\n",
    "    'Cicadomorpha':'Insects',\n",
    "    'primates':'Mammals',\n",
    "    'bats':'Mammals',\n",
    "    'mosses':'Mosses',\n",
    "    'flies':'Insects',\n",
    "    'modern sharks':'Fishes',\n",
    "    'true bugs':'Insects',\n",
    "    'rays':'Fishes',\n",
    "    'Hymenoptera':'Insects',\n",
    "    'nematodes':'Other inverebrates',\n",
    "    'Myliobatiformes':'Fishes'   \n",
    "}\n",
    "\n",
    "for i in range(len(spec_df)):\n",
    "    if spec_df.at[i,'Taxonomy'] in taxo_dict.keys():\n",
    "        spec_df.at[i,'Taxonomy'] = taxo_dict[ spec_df.at[i,'Taxonomy'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61ee53",
   "metadata": {},
   "source": [
    " ## BIOME from WWF Terrestrial Ecoregions of the World\n",
    " This section fills the column named BIOME that indicates the terrestrial ecoregions for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d891a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function and module required\n",
    "import geopandas as gpd\n",
    "\n",
    "def get_BIOME(df, LonColIdx, LatColIdx, path = \"C:\\\\Users\\\\yanghao\\\\Downloads\\\\ecology_map\\\\official\\\\wwf_terr_ecos.shp\"):\n",
    "    '''\n",
    "    Get Terrestrial ecosystems and BIOME from WWF based on coordinates. Geopandas required; wwf_terr_ecos.shp required \n",
    "    \n",
    "    Parameters:\n",
    "        df: input dataframe which include coordinates (assume EPSG:4326)\n",
    "        LonColIdx: column index of the DD format of Longitude\n",
    "        LatColIdx: column index of the DD format of Latitude\n",
    "        path: the path of of file wwf_terr_ecos.shp\n",
    "\n",
    "    Return:\n",
    "        The DataFrame with two additional columns indicating detailed ecology name and BIOME\n",
    "    '''\n",
    "\n",
    "    # check if input LonColIdx or LatColIdx is int\n",
    "    if (type(LonColIdx) is not int) | (type(LatColIdx) is not int):\n",
    "        raise TypeError('input LonColIdx or LatColIdx must be Int')\n",
    "\n",
    "    wwf = gpd.read_file(path).to_crs('EPSG:4326')\n",
    "    df2 = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.iloc[:,LonColIdx], df.iloc[:,LatColIdx]))\n",
    "    df2.crs = 'EPSG:4326'\n",
    "    df2['wwf_ecology'] = ''\n",
    "    df2['BIOME_num'] = ''\n",
    "    df2['BIOME'] = ''\n",
    "\n",
    "    habitat_dict = {\n",
    "        1: 'Tropical & Subtropical Moist Broadleaf Forests',\n",
    "        2: 'Tropical & Subtropical Dry Broadleaf Forests',\n",
    "        3: 'Tropical & Subtropical Coniferous Forests',\n",
    "        4: 'Temperate Broadleaf & Mixed Forests',\n",
    "        5: 'Temperate Conifer Forests',\n",
    "        6: 'Boreal Forests/Taiga',\n",
    "        7: 'Tropical & Subtropical Grasslands, Savannas & Shrublands',\n",
    "        8: 'Temperate Grasslands, Savannas & Shrublands',\n",
    "        9: 'Flooded Grasslands & Savannas',\n",
    "        10: 'Montane Grasslands & Shrublands',\n",
    "        11: 'Tundra',\n",
    "        12: 'Mediterranean Forests, Woodlands & Scrub',\n",
    "        13: 'Deserts & Xeric Shrublands',\n",
    "        14: 'Mangroves',\n",
    "        98: 'Lake',\n",
    "        99: 'Rock and Ice',\n",
    "        100: 'Others'\n",
    "    }\n",
    "\n",
    "    for i in range(len(df2)):\n",
    "            for j in range(len(wwf)):\n",
    "                if df2.at[i,'geometry'].within(wwf.at[j,'geometry']):\n",
    "                    df2.at[i,'wwf_ecology'] = wwf.at[j,'ECO_NAME']\n",
    "                    df2.at[i,'BIOME_num'] = wwf.at[j,'BIOME']\n",
    "                    df2.at[i,'BIOME'] = habitat_dict[ df2.at[i,'BIOME_num'] ]\n",
    "                    break\n",
    "            else:\n",
    "                df2.at[i,'wwf_ecology'] = 'unknown'\n",
    "                df2.at[i,'BIOME_num'] = 100\n",
    "                df2.at[i,'BIOME'] = 'Others'\n",
    "    \n",
    "    return df2\n",
    "\n",
    "# load occurrence data for each species, which is obtained from GBIF DATABASE\n",
    "\n",
    "occurrence_df = pd.read_csv(r'PATH_TO_OCCURRENCE_DATASET') # Obtained from GBIF database; see R script \n",
    "occurrence_df2 = get_BIOME(occurrence_df, LonColIdx, LatColIdx)\n",
    "summary = occurrence_df2.groupby('Species')['BIOME'].value_counts().unstack().fillna(0)\n",
    "\n",
    "summary2 = summary.copy()\n",
    "summary['BIOME'] = ''\n",
    "\n",
    "for i in list(pd.unique(occurrence_df2['Species'])):\n",
    "    summary.at[i,'BIOME'] = summary2.loc[i,].idxmax()\n",
    "\n",
    "summary['Species'] = summary.index\n",
    "spec_df.merge(summary.loc[:,['Species', 'BIOME']], how = 'left', on = 'Species')\n",
    "\n",
    "# For these species that have no occurrences data on GBIF, we use populations coordinates to obtain the BIOME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6817c0",
   "metadata": {},
   "source": [
    "## Habitat_breeding & Habitat_adulthood\n",
    "Given the speciaty of some fish species, we decided to split the Habitat column into Habitat_breeding & Habitat_adulthood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60207c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df['Habitat_breeding'] = ''\n",
    "spec_df['Habitat_adulthood'] = ''\n",
    "\n",
    "for i in range(len(spec_df)):\n",
    "    if spec_df.at[i,'Taxonomy'] in ['Birds', 'Reptiles', 'Woody plants','Herbaceous plants','Insects','Mosses','Fungi']:\n",
    "        spec_df.at[i, 'Habitat_breeding'] = 'Terrestrial'\n",
    "        spec_df.at[i, 'Habitat_adulthood'] = 'Terrestrial'\n",
    "    elif spec_df.at[i,'Taxonomy'] == 'Amphibians':\n",
    "        spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "        spec_df.at[i, 'Habitat_adulthood'] = 'Terrestrial'\n",
    "    elif spec_df.at[i,'Taxonomy'] == 'Fishes':\n",
    "        if 'potamodromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Freshwater'\n",
    "        elif 'anadromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Marine'\n",
    "        elif 'catadromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Marine'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Freshwater'\n",
    "        elif 'amphidromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = ''\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = ''\n",
    "        elif 'oceanodromous' in spec_df.at[i,'fishbase']:\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Marine'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Marine'\n",
    "        elif ('marine' in spec_df.at[i,'fishbase']) & ('freshwater' not in spec_df.at[i,'fishbase']):\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Marine'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Marine'\n",
    "        elif ('freshwater' in spec_df.at[i,'fishbase']) & ('marine' not in spec_df.at[i,'fishbase']):\n",
    "            spec_df.at[i, 'Habitat_breeding'] = 'Freshwater'\n",
    "            spec_df.at[i, 'Habitat_adulthood'] = 'Freshwater'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24320228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spec_df.to_excel('species_upload_HabitatNotCompleted.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
